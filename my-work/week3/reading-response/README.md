Response to "Automating Inequality w Virginia Eubanks"


1.How to technical tools promise to "fair out" the remaining discrimination that exist in social/welfare systems? In how far can they succeed, in which ways do they fail?


The computer won't make its decision according to its user's color, gender, social identity, etc. However, bias can influence a human's decision making process easily, which may cause discriminations. Technical tools will only judge from what the information has been input. It can be sure in making objective decisions.
But accrding to Virjinia Eubanks, people find it cold and heartless when engaging with the technical tools. The judgement made by these tools also lack of the consideration in the moral status in each case. However, morality in an important distinction of human society from others. So, it still has a long way on inputing the moral diagnosis in to its program.



2.Imagine, what could this (following quotes) mean in the widest sense?
"The state doesn't need a cop to kill a person" and "electronic incarceration"


This shows the importance of social control. A person can not only be affected negatively through direct physical harm, but also a person can be killed by cutting his/her connection with the society. When a people get isolated from the social system, it also means they are cut from their living necessities. They won't have a shelter, no food, no medical treatment. The segragating decision made by a electronic device will impact on all aspects of a person'life, and kills him/her gradually.

3.What do you understand this to mean?
"systems act as a kind of 'empathy-overwrite'"

People has to write about their cirsis status to get the service, to get there score higher.
They not only have to make themselves more vulnerable, but also ther information can be easily accessed to by anybody according to the current federal law.
People is being judged according to their history and reports. And the standard is unknown. They were being report for asking help. The database is limited and the accessed user is limitedã€‚ Bucause they are using public service instead of private ones. Be trapped in the feedback loop.

First, for the people who need the social service's help, they are ranking by the severeness of their current status. Therefore, poor people have to rewrite about there crisis in order to get the score higher.
Second, people are being judged their potential crisis through their previous records. However, only the ones who use public facilities can be record and the ones who use private means won't.

4.China is much more advanced and expansive when it comes to applying technical solutions to societal processes or instant challenges (recent example). Try to point example cases in China that are in accordance with or in opposition to the problematics discussed in the podcast. Perhaps you can think of
"technical systems not well thought-through about what their impact on human beings is"
